{"cells":[{"cell_type":"markdown","metadata":{"id":"mT5WMv1s9juc"},"source":["\n","\n","> # **Advanced Image Processing**\n","\n","\n","\n","# Blob Detection\n","## What are blobs and why do we care?\n","In essence, \"blob detection\" is the process of searching for and identifying bright spots on a dark background, or dark spots on a light background. The \"blobs\" can correspond to any number of physical phenomena. In astronomy, for example, this can be relevant if you have an image of a part of the sky and want to identify something like galaxies. You might be wondering though, why not just look at an image yourself and pick out blobs \"by eye\"? In our example of identifying galaxies in an astronomical image, a systematic way of doing this may be beneficial for several reasons: \n","- you may have faint objects in your image the are difficult to distinguish from the background\n","- you may have a crowded field where bright points are close enough together that they are difficult to disentangle\n","- you may have a large dataset where it would just take you a long time to go through everything by hand\n","- you may want to define where a blob \"ends\" in a systematic way so that your blob definition is consistent across all objects you identify\n","\n","These are just some of the reasons why a systematic approach to identifying blobs in images could be beneficial. Checking the output of your algorithm by eye, however, is wise to make sure that it is not outputting nonsense.\n","\n","Let's get started with first reading in our first astronomical image; a nearby group of galaxies! Astronomical images are stored as \"fits\" files, this is essentially a table that contains the information of how bright the sky is at each pixel in your image, and a \"header\", which contains information about how pixels translate into coordinates on the sky, what instrument was used, and the units of the image for example. We will read the fits file into a numpy array using the package called astropy (see http://docs.astropy.org/en/stable/index.html for documentation). This package streamlines the process of working with astronomical images in Python. "]},{"cell_type":"markdown","metadata":{"id":"0Xk_OPfKfhqs"},"source":["First we will import a few packages that we are going to use throughout this section: skimage will allow us to run the blob detection algorithms, matplotlib  will allow us to plot our data, astropy will allow us to read \"fits\" files,  and numpy will let us do cool things with arrays."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9NHDd2U9qb3"},"outputs":[],"source":["from skimage.feature import blob_dog, blob_log, blob_doh\n","import matplotlib.pyplot as plt\n","from astropy.io import fits\n","import numpy as np\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LaYMqdb7f62x"},"source":["This line reads the fits file --> data table and header."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lw7fzmD6f3fA"},"outputs":[],"source":["hdu = fits.open('./RSCG1.fits')"]},{"cell_type":"markdown","metadata":{"id":"veYtEdqigH_7"},"source":["# Exercise 5: hdu\n","\n","What is the type of hdu? What happens when you print hdu?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxbDR5sPgXSR"},"outputs":[],"source":["#Insert your code here:\n","\n","print(type(hdu))\n","print(hdu)"]},{"cell_type":"markdown","metadata":{"id":"K4vo4LxTgk5S"},"source":["This line reads the data associated with the header into a numpy array. A fits file can have more than one header, and since Python indices start at 0, we tell Python to read the data associated with the first (and only) header associated with this fits file. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iE6CXDl1gIUu"},"outputs":[],"source":["image = hdu[0].data\n","# This line closes the fits file because we don't need it anymore; we've already read the data into an array.\n","hdu.close()"]},{"cell_type":"markdown","metadata":{"id":"28HzHjCyg7K6"},"source":["# Exercise 6: Astronomical Images\n","What is the type of the image? What happens when you print image? What are the dimensions of image? What are the minimum and maximum values?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDlhy8xphROn"},"outputs":[],"source":["#Insert your code here:\n","\n","print(type(image))\n","print(image)\n","print(image.shape)\n","print(np.max(image))\n","print(np.min(image))\n"]},{"cell_type":"markdown","metadata":{"id":"oq6BC26p93gd"},"source":["That's it, you've now read your astronomical image into Python and can work with the data and analyze it! Let's visualize the data now to get an idea of what it is we are actually dealing with."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImahX30f94Md"},"outputs":[],"source":["# imshow will map the 2D array (our data), and origin='lower' tells imshow to plot (0,0) in the bottom left corner. \n","plt.imshow(image,origin='lower')\n","plt.colorbar()\n","plt.show()\n","\n","\n","# EXERCISE: What happens if you remove origin='lower'? How does the mapping of the image change?"]},{"cell_type":"markdown","metadata":{"id":"_eqZ6pcH-DDC"},"source":["We can now run some blob finding algorithms on this data set and see what we find and if it makes sense! For this, we will use the scikit-image package which is an image processing pacakge in Python. This package has three algorithms for detecting blobs (all discussed here: https://en.wikipedia.org/wiki/Blob_detection):\n","- Laplacian of Gaussian\n","- Difference of Gaussian\n","- Determinant of Hessian\n","\n","This is great, but what does this actually mean? How do they work? What's the difference between them?\n","\n","### Laplacian of Gaussian\n","This algorithm starts by smoothing (blurring) the entire image with a two-dimensional Gaussian function: \n","\n","$$\\begin{align} g(x,y,\\sigma) = \\frac{1}{2\\pi\\sigma^2} e^\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right) \\end{align}$$ \n","\n","where $(x,y)$ correspond to pixel coordinates on your image, and $\\sigma$ represents the \"size\" or \"width\" of the Gaussian function. The algorithm then performs a mathematical computation called taking the \"Laplacian\", however we will not go into the details of that. What this effectively gives you is strong responses for blobs of size $\\sqrt{2}\\sigma$. This means that the algorithm is most sensitive to detecting blobs that have a similar size to that of the Gaussian function that you smooth your image with in the first place. In order to detect blobs of varying size, you need to use an approach that allows you to smooth your image with Gaussians of varying sizes to try to match the scale of potential blobs. This approach is the most accurate but also the slowest approach, especially for the largest blobs, because it needs to smooth the image with a larger Gaussian.\n","\n","The scikit-image function \"blob_log\" (https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.blob_log) has this capability. To run it, we simply need to call the function and provide it with the correct input parameters. In the following piece of code, this is what we are going to provide the function with:\n","- **image** to run the blob detection on\n","- **min_sigma**: the minimum size for the Gaussian that will be used to smooth the image; this corresponds to the smallest blobs we expect in the image\n","- **max_sigma**: the maximum size for the Gaussian that will be used to smooth the image; this corresponds to the largest blobs we expect in the image\n","- **num_sigma**: the number of sizes to consider between the minimum and maximum\n","- **threshold**: relates to how faint of a blob you can detect; a smaller threshold will detect fainter blobs\n","\n","The call to this function will output a list of x and y coordinates corresponding to the center of each blob, as well as the \"size\" of the Gaussian that it used to find that blob. Let's try it out!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hcWTUqu-ELT"},"outputs":[],"source":["# This line calls the blob detection (Laplacian of Gaussian function) on our galaxies image with the parameters that\n","# we provide\n","blobs_log = blob_log(image, min_sigma = 2, max_sigma=9, num_sigma=8, threshold=.05)"]},{"cell_type":"markdown","metadata":{"id":"niz5VnKQjwmi"},"source":["# Exercise 7: Blobs \n","What kind of output does blobs_log provide? What are its dimensions? What does the length of blobs_log physically correspond to?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yC0CozDjvMD"},"outputs":[],"source":["input(\"What kind of output is blobs_log?\")\n","input(\"What are its dimension?\")\n","input(\"What does the length of blobs_log physically correspond to?\")"]},{"cell_type":"markdown","metadata":{"id":"OlVjfolFkTyG"},"source":["## Data from the blob finder \n","\n","The first column of blobs_log (blobs_log[0]) is the y-coordinate, the second column (blobs_log[1]) is the x-coordinate, and the third column (blobs_log[2]) is the \"size\" of the Gaussian that was used to detect the blob. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqupsIF2-I0A"},"outputs":[],"source":["# In this line we use the third column to calculate the radius of the blob itself.\n","blobs_log[:, 2] = blobs_log[:, 2] * np.sqrt(2)"]},{"cell_type":"markdown","metadata":{"id":"wFMGgsQvmTE7"},"source":["## Plotting the blobs\n","Now we'll plot the blobs onto our image! For this, we will create circles with plt.Circle using the corrdinate and radius information we have from blobs_log. Then we will use add_patch to add that circle to our image. Since the plotting software needs information about the axes of the image in order to know where each circle goes, we use plt.gca() which means \"Get Current Axis\" and store the axis information into \"ax\". Then when we add the circle patches to the image, they will appear in the correct places. Finally, since there is more than one blob, we will create the circular patches and add them to the image one-by-one using a while loop. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQToTxHRmQ1-"},"outputs":[],"source":["ax = plt.gca()\n","ax.imshow(image,origin='lower')\n","cnt = 0\n","while cnt < len(blobs_log):\n","    c = plt.Circle((blobs_log[cnt][1], blobs_log[cnt][0]), blobs_log[cnt][2], color='white', linewidth=2, fill=False)\n","    ax.add_patch(c)\n","    cnt = cnt + 1\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1Fndbo84n--g"},"source":["#Exercise 8: Blob Parameters\n","\n","Play around with the input parameters in the following block of code, then run it to see how changing they will affect the number (more blobs fewer blobs, no blobs) and type of blobs detected (bigger, smaller, brighter, fainter). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsgp4YYAokM7"},"outputs":[],"source":["blobs_log = blob_log(image, min_sigma = 2, max_sigma=9, num_sigma=8, threshold=.05)\n","\n","### Play with the paramters above this line ###\n","blobs_log[:, 2] = blobs_log[:, 2] * np.sqrt(2)\n","ax = plt.gca()\n","ax.imshow(image,origin='lower')\n","cnt = 0\n","while cnt < len(blobs_log):\n","    c = plt.Circle((blobs_log[cnt][1], blobs_log[cnt][0]), blobs_log[cnt][2], color='white', linewidth=2, fill=False)\n","    ax.add_patch(c)\n","    cnt = cnt + 1\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"erYchCKupIe3"},"source":["Write down your findings below, such as what parameters give you no blobs, how does changing the parameters affect the results, and anything else that you find interesting!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GRj1Rxfn8aS"},"outputs":[],"source":["# RECORD YOUR FINDINGS HERE"]},{"cell_type":"markdown","metadata":{"id":"A_AOKn7T-N0T"},"source":["### Difference of Gaussian (DoG)\n","This algorithm is an approximation of the Laplacian of Gaussian, where rather than actually computing the \"Laplacian\" of the Gaussian that we mentioned above, DoG approximates this computation by taking the difference of two successively smoothed (blurred) images. Blobs are then detected as bright-on-dark spots in these difference images. This algorithm has the same disadvantage for larger blobs as the Laplacian of Gaussian algorithm.\n","\n","To run this algorithm, we use the function \"blob_dog\" (https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_dog), which takes the same parameters as blob_log, except for **num_sigma**, because the algorithm needs to take the difference between successive smoothings so it figures out the number of times it needs to smooth the image. This function returns the same type of array as \"blob_log\" : (y-coord, x-coord, size). "]},{"cell_type":"markdown","metadata":{"id":"wbfDS6CFp-tz"},"source":["#Exercise 9: DoG \n","\n","Fill in the input parameters for the call to the blob_dog function and run the code. How is the result from this function different from the previous one?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eoIhGs2t-OXK"},"outputs":[],"source":["blobs_dog = blob_dog(image, min_sigma=2,max_sigma=9, threshold=0.05)\n","blobs_dog[:, 2] = blobs_dog[:, 2] * np.sqrt(2)\n","\n","ax = plt.gca()\n","ax.imshow(image,origin='lower')\n","cnt = 0\n","while cnt < len(blobs_dog):\n","    c = plt.Circle((blobs_dog[cnt][1], blobs_dog[cnt][0]), blobs_dog[cnt][2], color='white', linewidth=2, fill=False)\n","    ax.add_patch(c)\n","    cnt = cnt + 1\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tmNCqq5J-Q1V"},"source":["### Determinant of Hessian\n","The final option that scikit-image provides is the Determinant of Hessian algorithm. This algorithm performs a different kind of mathematical operation on the smoothed images, it calculates the Hessian matrix of the image (but we won't go into that), and searches for maxima in this matrix. It it the fastest approach, but it is also less accurate and has trouble finding very small blobs. \n","\n","To try it out, we will run the function \"blob_doh\" (https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_doh), which takes as input the same parameters as the \"blob_log\" function. Let's try it out!"]},{"cell_type":"markdown","metadata":{"id":"uxHbrWp6D6Fk"},"source":["# Exercise 10: DoH\n","Fill in the input parameters for the call to the blob_doh function and run the code. How is the result from this function different from the previous one? How were the input parameters different from the previous algorithms?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKM6DFpM-THY"},"outputs":[],"source":["blobs_doh = blob_doh(image, min_sigma=2, max_sigma=9, num_sigma=8, threshold=.001)\n","\n","ax = plt.gca()\n","ax.imshow(image,origin='lower')\n","cnt = 0\n","while cnt < len(blobs_doh):\n","    c = plt.Circle((blobs_doh[cnt][1], blobs_doh[cnt][0]), blobs_doh[cnt][2], color='white', linewidth=2, fill=False)\n","    ax.add_patch(c)\n","    cnt = cnt + 1\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1bh24h2OEIKZ"},"source":["# Exercise 11: Blobs 2\n","How do the three algorithms compare to each other? Do their results agree with what you would intuitively call a blob? Do you trust one algorithm more than another? \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9_cnu8lEa90"},"outputs":[],"source":["# RECORD YOUR THOUGHTS HERE"]},{"cell_type":"markdown","metadata":{"id":"FJqe3137EkWo"},"source":["\n","---\n","\n","># **Particle Tracking**\n","\n","Now that we have learned several image processing techniques, we are ready to put them together in an application. In physics, there is an experiment called the Monopole Ion Trap that uses electric fields to trap particles as show below.\n","\n","![alt text](https://imgur.com/1cBAcEc.gif)\n","\n","The basic priciple is that the particle is attracted to and repeled by the rod at the top of the image. In the image above, we have a very stable, well behaved, trap in which the ion just goes back and forth between two locations. However, under certain curcumstances, the particle may start to behave erratically, as shown below.\n","\n","![alt text](https://imgur.com/Z575ope.gif)\n","\n","We would like to track the particle so that we can study its position and velocity.\n","\n","Lets start by importing the two movies shown above into python. We have saved each movie, image by image, inside of folders on the computers. So we will import them as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqEbyjL5vPVb"},"outputs":[],"source":["# we import the operating system library OS to help us import many files at once\n","import os\n","\n","folder_location = \"./P1\"\n","#the following line will navigate python to the correct foler. chdir stands for change directory.\n","os.chdir(folder_location)\n","#the following line return a list of file names in the folder\n","files = os.listdir()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5QCoW3YOvPVc"},"source":["Now is a good time to notice that we don't actually need the entire image to do this computation. The only thing we really need is the region the particle travels within, as shown below \n","\n","![alt text](https://imgur.com/oXLY4RF.gif)\n","\n","This is called the Region of Interest (ROI) of an image so we will crop every single image as we import it. Lets do that by importing a test image and checking how we want to crop it:"]},{"cell_type":"markdown","metadata":{"id":"uMbJls33vPVc"},"source":["# Exercise 11: Cropping 2\n","\n","Find the correct copping location by chaning the slice location"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxvQcuWhvPVd"},"outputs":[],"source":["test_image = io.imread(files[0])\n","plt.imshow(test_image[210::], cmap = cm.gray)\n"]},{"cell_type":"markdown","metadata":{"id":"t0doG1pFvPVd"},"source":["Now that we know where we want to crop the images, we can do so automatically for all of the images in the folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ScahByZvPVd"},"outputs":[],"source":["# the following line creates an empty list that we will populate with the images as we import and crop them. \n","#That is, ROI is a list of matrices, each one representing an image.\n","ROIs = []\n","\n","# the following for-loop imports the images\n","for image in files:\n","    ROIs.append(io.imread(image)[210::])\n","\n","# to make sure we are doing things correctly, lets see what the 17th image in the list is\n","plt.imshow(ROIs[16], cmap=cm.gray)"]},{"cell_type":"markdown","metadata":{"id":"LFJEvasPvPVd"},"source":["Looks good. Okay, now that we have all of the images imported, we want to run a blob finding algorithm that finds the position of the blob in each of the images. However, there are \"specles\" in the background, so make sure that your blob finding parameters are set correctly."]},{"cell_type":"markdown","metadata":{"id":"WlCDDofpvPVe"},"source":["# Exercise 12: Particle Tracking\n","\n","\n","The goal is for you to use the examples we have provided above to write your own code to systematically find the particles in the ROI list. A general outline of the code is provided below, but if you need further help feel free to ask. \n","\n","general outline:\n","1. choose one of the images in the ROI list to test your parameters on\n","2. apply one of the blob finding techniques to the image (take a look at earlier examples if needed)\n","3. make a for-loop that applies this technique to all of the images in ROI and collects all of the outputs needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAYJcHLivPVe"},"outputs":[],"source":["#student solution goes here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9WGXZdOvPVe"},"outputs":[],"source":["#instructor solution\n","\n","particles = []\n","\n","for image in ROIs:\n","    blob = blob_log(image, min_sigma = 5, max_sigma=10, num_sigma=2, threshold=.1)\n","    particles.append(blob)\n","    \n","#print(particles)"]},{"cell_type":"markdown","metadata":{"id":"dZE6mRjDvPVe"},"source":["We should now have a list of particle locations and sizes. Note that the size information is not important to this application, so we can get rid of it. In general, we find it easier to work with big complicated lists using numpy, so first we will convert the list into a numpy array, and then clean it up."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_JXb40UvPVf"},"outputs":[],"source":["#the following line converts the list into a numpy array\n","particles = np.array(particles)\n","#the following line cleans up array to make it look nicer\n","particles = particles[::,0]\n","#this shows us what they array looks like.\n","print(particles)"]},{"cell_type":"markdown","metadata":{"id":"fWZYt2yivPVf"},"source":["# Data Analysis\n","\n","Great, using a ROI made this computation faster, and it made sure that the particle was easy to find. Unfortunately it also introduced a small offset error in the verticle position of the particle. This can be seen by taking a look at the picture below:\n","\n","![alt text](https://imgur.com/aI3a3Ve.gif)\n","\n","To correct for this error we simply have to add an offset to the y position of the particle list."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KUTwC7YvPVf"},"outputs":[],"source":["for n, blob in enumerate(particles):\n","    particles[n] = np.add(blob, [210,0,0])\n","print(particles)"]},{"cell_type":"markdown","metadata":{"id":"oErtCwKNvPVf"},"source":["The final step is to turn these pixel locations into measurements of distance between the particle and the center of the rod. To do this, we will use the usual distance formula:\n","\n","![alt text](https://i.imgur.com/xsRJGbR.png)\n","\n","where (y_2, x_2) is the location of the center of the rod and (y_1, y_2) is the location of the particle. From previous measurements, the experimenters know that the center of the rod is approximately at \n","\n","y_2 = 83\n","\n","x_2 = 137\n","\n","so we can change all of the particle *location* data to particle *distance* data as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okkDZYRsvPVg"},"outputs":[],"source":["distances = []\n","for particle in particles:\n","    distance = np.sqrt((83 - particle[0])**2 + (137-particle[1])**2)\n","    distances.append(distance)\n","    \n","distances = np.array(distances)\n","#print(distances)"]},{"cell_type":"markdown","metadata":{"id":"a0G8dT89vPVg"},"source":["Great, so now we have the the distances of the particles from the center of the rod for each movie. The experimenters also know two important pieces of information. \n","\n","1. the camera was taking 2360 pictures per second (FPS), so the time between each image is 1/2360 seconds. \n","2. the distance between each pixel 5.9 micron = .0059 millimeters (mm)\n","\n","we can use this information to make a plot of the particle's distance as a function of time with proper units."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xg-shiVgvPVg"},"outputs":[],"source":["time = np.linspace(0,len(distances)/2360, len(distances) )\n","distances = distances*.0059\n","plt.plot(time,distances)\n","plt.xlabel('time(s)')\n","plt.ylabel('distance(mm)')"]},{"cell_type":"markdown","metadata":{"id":"TdLDcimPvPVh"},"source":["## Congratulations!\n","\n","You just did particle tracking. Now we'll quickly demonstrate how to find the velocity of the particle.\n","\n","Recall that the definition of velocity is simply distance/time. Since we know that the time between pictures is 1/2360 seconds, all we have to do is calculate the distance the particle moved between each frame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-GsRJX7vPVh"},"outputs":[],"source":["velocities = []\n","for n in range(len(distances)):\n","    if n < (len(distances)-1):\n","        velocity = (distances[n+1] - distances[n])*2360\n","        velocities.append(velocity)\n","#print(velocities)"]},{"cell_type":"markdown","metadata":{"id":"FBOL8ycIvPVh"},"source":["Sometime is it useful/interesting to see the velocity data in a \"phase diagram\", which is just a plot of the position vs the velocity:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSKhf4C3vPVh"},"outputs":[],"source":["plt.scatter(distances[:-1:],velocities, )\n","plt.xlabel('distance(mm)')\n","plt.ylabel('velocity(mm/s)')"]},{"cell_type":"markdown","metadata":{"id":"YPDChI1yvPVi"},"source":["As you can see, the stable particle makes a circle in these \"phase diagrams\". As you can try (below), the unstable particle will produce sometehing that looks like scribles instead. Phase diagrams are often used to quickly check the stability of a particle, without having to watch the full movie."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}